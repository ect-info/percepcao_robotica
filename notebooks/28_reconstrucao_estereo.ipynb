{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table style=\"width: 100%; margin-left: auto; margin-right: auto;\" border=\"0\">\n",
    "    <tr>\n",
    "        <td rowspan=\"3\"> <img src=\"brasao_ufrn.png\" width=\"150\"/> </td>\n",
    "        <td style=\"text-align: center\">  Escola de Ciências e Tecnologia </td>\n",
    "        <td rowspan=\"3\" style=\"text-align: center\"> UFRN<br> CT<br> PPGEMECA </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: center\"> PPGEMECA - Percepção Robótica </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p style=\"text-align: left;\">Prof. Bruno Silva<br>\n",
    "                                         Prof. Marcelo Nogueira</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reconstrução Estéreo I\n",
    "\n",
    "> Reconstrução estéreo: obter as coordenadas 3D de uma cena a partir de um par de imagens estéreo\n",
    "\n",
    "Permite que sejam obtidas a distância e direção de *features* presentes na imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reconstrução Estéreo II\n",
    "\n",
    "Assumindo que as câmeras foram calibradas e possuem as imagens retificadas,\n",
    "a reconstrução se dá por:\n",
    "\n",
    "1. Obtenção de correspondências: um mesmo ponto é achado na imagem esquerda e direita\n",
    "2. Cálculo da disparidade (diferença na coordenada $x$ na imagem de um mesmo ponto)\n",
    "3. Triangulação: cálculo da profundidade $Z_c$ a partir da disparidade e parâmetros extrínsecos\n",
    "4. Cálculo de $X_c$ e $Y_c$ dado $Z_c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstrução Estéreo III\n",
    "\n",
    "Observe à esquerda um exemplo de par estéreo retificado: após retificação, os planos das duas imagens são paralelos e as linhas epipolares de ambas as imagens coincidem, para facilitar o processo de\n",
    "busca por correspondências. A retificação corta e \"entorta\" a imagem, além de introduzir regiões nulas.\n",
    "\n",
    "À direita, um exemplo de reconstrução 3D a partir de imagens estéreo.\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"28_reconstrucao_estereo/stereo_rectification.png\" style=\"margin:auto; width: 600px;\"/></td>\n",
    "<td><img src=\"28_reconstrucao_estereo/stereo_reconstruction.png\" style=\"margin:auto; width: 600px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">Imagens da documentação da OpenCV </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstrução Estéreo IV\n",
    "\n",
    "Este documento mostra como obter uma reconstrução estéreo\n",
    "a partir de imagens estéreo retificadas e calibradas.\n",
    "\n",
    "São exemplos deste tipo de imagens as imagens de odometria\n",
    "visual do *dataset* KITTI [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Correspondência Estéreo I\n",
    "\n",
    "O primeiro passo para obter-se uma reconstrução estéreo é computar correspondências\n",
    "entre pontos da imagem esquerda e da imagem direita.\n",
    "\n",
    "Isto é realizado por meio de algoritmos do tipo *block matching* (casamento por blocos):\n",
    "dado uma janela (bloco) da imagem esquerda, a sua correspondência é buscada na imagem\n",
    "direita \"deslizando-se\" o bloco na imagem direita, até que a similaridade seja a maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência Estéreo II\n",
    "\n",
    "**Mapa de disparidade**: imagem que contém, em cada uma de suas posições, o valor da disparidade (em pixels).\n",
    "\n",
    "Um mapa de disparidade é computado pelos algoritmos de correspondência estéreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência Estéreo III\n",
    "\n",
    "Na biblioteca OpenCV, estão presentes pelo menos 2 algoritmos para correspondência\n",
    "estéreo:\n",
    "\n",
    "1. `StereoBM`: *block matching* simples $\\rightarrow$ baixo custo computacional mas com mapa resultante de precisão limitada\n",
    "2. `StereoSGBM`: *semi global block matching* $\\rightarrow$ resulta em mapas de qualidade superior a um maior custo computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência Estéreo - Funções da OpenCV I\n",
    "\n",
    "`StereoBM.create`: cria um objeto do tipo *block matching* para computar correspondências\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "- `numDisparities`: número de disparidades esperado. Precisa ser múltiplo de 16\n",
    "- `blockSize`: tamanho da janela de busca. Precisa ser ímpar e maior do que 5\n",
    "\n",
    "`compute`: faz o objeto computar correspondências entre duas imagens (esquerda e direita, nesta ordem) fornecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calcula correspondência estéreo\n",
    "para um par de imagens retificadas\n",
    "utilizando Block Matching simples.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def main():\n",
    "\n",
    "    img_l = cv2.imread('kitti00_00l.png', cv2.IMREAD_GRAYSCALE)\n",
    "    img_r = cv2.imread('kitti00_00r.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    num_disparities = 96\n",
    "    block_size = 11\n",
    "    matcher = cv2.StereoBM.create(numDisparities=num_disparities, blockSize=block_size)\n",
    "    \n",
    "    img_disp = matcher.compute(img_l, img_r)\n",
    "    plt.imshow(img_disp, 'gray')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência Estéreo - Funções da OpenCV II\n",
    "\n",
    "`StereoSGBM.create`: cria um objeto do tipo *semi global block matching* para computar correspondências\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "- `numDisparities`: número de disparidades esperado. Precisa ser múltiplo de 16\n",
    "- `minDisparity`: disparidade mínima esperada\n",
    "- `blockSize`: tamanho da janela de busca. Precisa ser ímpar\n",
    "- `P1`: penalidade da disparidade por mudança de mais ou menos 1 entre pixels vizinhos. Quanto maior o valor, mais suave será a disparidade\n",
    "- `P2`: penalidade da disparidade por mudança maior que 1 entre pixels vizinhos. Quanto maior o valor, mais suave será a disparidade\n",
    "- `mode`: utilizar `cv2.STEREO_SGBM_MODE_SGBM_3WAY`\n",
    "\n",
    "`compute`: faz o objeto computar correspondências entre duas imagens (esquerda e direita, nesta ordem) fornecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calcula correspondência estéreo\n",
    "para um par de imagens retificadas\n",
    "utilizando Semi Global Block Matching.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def main():\n",
    "\n",
    "    img_l = cv2.imread('kitti00_00l.png', cv2.IMREAD_GRAYSCALE)\n",
    "    img_r = cv2.imread('kitti00_00r.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    sad_window = 6\n",
    "    num_disparities = sad_window*16\n",
    "    block_size = 11\n",
    "    matcher = cv2.StereoSGBM.create(numDisparities=num_disparities,\n",
    "                                    minDisparity=0,\n",
    "                                    blockSize=block_size,\n",
    "                                    P1 = 8 * 3 * sad_window ** 2,\n",
    "                                    P2 = 32 * 3 * sad_window ** 2,\n",
    "                                    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "                                    )\n",
    "    \n",
    "    img_disp = matcher.compute(img_l, img_r)\n",
    "    plt.imshow(img_disp, 'gray')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disparidade\n",
    "\n",
    "A imagem abaixo exibe o mapa de disparidade resultante para as imagens de exemplo\n",
    "com o algoritmo SGBM.\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"28_reconstrucao_estereo/disparity.png\" style=\"margin:auto; width: 800px;\"/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondência Estéreo - Funções da OpenCV III\n",
    "\n",
    "Em comum a ambas as funções:\n",
    "\n",
    "- Parametrizar os algoritmos é uma tarefa necessária para cada aplicação específica\n",
    "- Parametrizar os algoritmos é feito em geral por tentativa e erro (ou uso de interface gráfica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Triangulação I\n",
    "\n",
    "A triangulação é o processo que resulta na profundidade de um ponto\n",
    "dada a sua disparidade:\n",
    "\n",
    "$$\n",
    "Z = \\frac{fT}{d},\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $f$ é a distância focal\n",
    "- $F$ é a linha de base (distância entre as câmeras)\n",
    "- $d$ é a disparidade\n",
    "\n",
    "**Como as imagens estão retificadas, a disparidade é calculada como sendo\n",
    "a diferença da coordenada x esquerda menos a da direita**\n",
    "$\\rightarrow d = x^r-x^l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulação II\n",
    "\n",
    "**Mapa de profundidade**: imagem que contém, em cada uma de suas posições, o valor da profundidade (em unidades de distância)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulação - Código\n",
    "\n",
    "O código a seguir mostra como obter um mapa de profundidade a partir\n",
    "da imagem de disparidade.\n",
    "\n",
    "A OpenCV possui uma função para isto (`reprojectTo3D`) mas não iremos utilizá-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def compute_disparity(img_l, img_r):\n",
    "    sad_window = 6\n",
    "    num_disparities = sad_window*16\n",
    "    block_size = 11\n",
    "    matcher = cv2.StereoSGBM.create(numDisparities=num_disparities,\n",
    "                                    minDisparity=0,\n",
    "                                    blockSize=block_size,\n",
    "                                    P1 = 8 * 3 * sad_window ** 2,\n",
    "                                    P2 = 32 * 3 * sad_window ** 2,\n",
    "                                    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "                                    )\n",
    "    \n",
    "    return matcher.compute(img_l, img_r).astype(np.float32)/16    \n",
    "\n",
    "def compute_depth(f, T, img_disp):\n",
    "    img_disp[img_disp == 0.0] = 0.1 # evita divisões por 0\n",
    "    img_disp[img_disp == -1.0] = 0.1 # evita valores inválidos na disparidade\n",
    "\n",
    "    img_depth = np.zeros(img_disp.shape)\n",
    "    return (f * T)/img_disp\n",
    "\n",
    "def main():\n",
    "\n",
    "    T = 0.54\n",
    "    f = 718.856\n",
    "\n",
    "    img_l = cv2.imread('kitti00_00l.png', cv2.IMREAD_GRAYSCALE)\n",
    "    img_r = cv2.imread('kitti00_00r.png', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img_disp = compute_disparity(img_l, img_r)\n",
    "    img_depth = compute_depth(f, T, img_disp)\n",
    "    print(f'min depth: {img_depth.min()}')\n",
    "    print(f'max depth: {img_depth.max()}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuvem de Pontos I\n",
    "\n",
    "**Nuvem de pontos**: conjunto de pontos (2D ou 3D), é a\n",
    "forma mais comum do resultado de uma reconstrução 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuvem de Pontos II\n",
    "\n",
    "Para obter as coordenadas 3D de um determinado ponto (ref. ao Sistema de Coordenadas de câmera),\n",
    "é preciso conhecer a sua profundidade $Z$. A partir dela, realiza-se o processo inverso da projeção:\n",
    "\n",
    "$$\n",
    "x = \\frac{f_x}{Z_c} X_c + c_x\n",
    "\\Rightarrow\n",
    "X_c = \\frac{Z_c(x - c_x)}{f_x}\n",
    "$$\n",
    "e\n",
    "$$\n",
    "y = \\frac{f_y}{Z_c} Y_c + c_y\n",
    "\\Rightarrow\n",
    "Y_c = \\frac{Z_c(y - c_y)}{f_y}\n",
    "$$\n",
    "onde $x$ e $y$ são as coordenadas de um ponto na imagem com profundidade $Z_c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa de Profundidade I\n",
    "\n",
    "A imagem abaixo exibe a nuvem de pontos resultante para as imagens\n",
    "de exemplo. Observe que ela contém muitos pontos com a profundidade\n",
    "máxima calculada (em vermelho).\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"28_reconstrucao_estereo/cloud_all.png\" style=\"margin:auto; width: 800px;\"/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa de Profundidade II\n",
    "\n",
    "A imagem abaixo exibe a nuvem de pontos após filtragem:\n",
    "os pontos com profundidade máxima foram modificados\n",
    "para conter $Z_c = 0$.\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"28_reconstrucao_estereo/cloud_filtered.png\" style=\"margin:auto; width: 800px;\"/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstrução 3D: Código/prática\n",
    "\n",
    "O código a seguir está estruturado para exibir uma nuvem de pontos\n",
    "3D computada a partir de um par de imagens estéreo.\n",
    "\n",
    "Implemente as funcionalidades que estão faltando como parte do projeto final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def compute_disparity(img_l, img_r):\n",
    "    sad_window = 6\n",
    "    num_disparities = sad_window*16\n",
    "    block_size = 11\n",
    "    matcher = cv2.StereoSGBM.create(numDisparities=num_disparities,\n",
    "                                    minDisparity=0,\n",
    "                                    blockSize=block_size,\n",
    "                                    P1 = 8 * 3 * sad_window ** 2,\n",
    "                                    P2 = 32 * 3 * sad_window ** 2,\n",
    "                                    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "                                    )\n",
    "    \n",
    "    return matcher.compute(img_l, img_r).astype(np.float32)/16    \n",
    "\n",
    "def compute_depth(f, T, img_disp):\n",
    "    img_disp[img_disp == 0.0] = 0.1 # evita divisões por 0\n",
    "    img_disp[img_disp == -1.0] = 0.1 # evita valores inválidos na disparidade\n",
    "\n",
    "    img_depth = np.zeros(img_disp.shape)\n",
    "    return (f * T)/img_disp\n",
    "\n",
    "def reconstruct_point(K, x, y, Z):\n",
    "    fx = K[0,0]\n",
    "    fy = K[1,1]\n",
    "    cx = K[0,2]\n",
    "    cy = K[1,2]\n",
    "\n",
    "    #utilize a inversa da projeção para computar cada ponto 3D\n",
    "    #X = ???\n",
    "    #Y = ???\n",
    "    return np.array([X, Y, Z]).T\n",
    "\n",
    "def generate_point_cloud(K, img_depth):\n",
    "    max_depth = img_depth.max()\n",
    "    cloud = []\n",
    "    for i in range(img_depth.shape[0]):\n",
    "        for j in range(img_depth.shape[1]):\n",
    "            Z = img_depth[i, j]\n",
    "            if Z == max_depth: # pontos com profundidade máxima recebem Z = 0 (possivelmente inválidos)\n",
    "                Z = 0\n",
    "            pt3D = reconstruct_point(K, j, i, Z)\n",
    "            cloud.append(pt3D)\n",
    "\n",
    "    return np.array(cloud)\n",
    "\n",
    "def view_point_cloud(points3D):\n",
    "    # implemente uma maneira de visualizar uma nuvem de pontos\n",
    "    # (matplotlib ou open3D)\n",
    "\n",
    "def main():\n",
    "\n",
    "    T = 0.54\n",
    "    f = 718.856\n",
    "    K = np.array([[718.856,       0, 607.192],\n",
    "                  [      0, 718.856, 185.215],\n",
    "                  [      0,       0,       1]])\n",
    "\n",
    "    img_l = cv2.imread('kitti00_00l.png', cv2.IMREAD_GRAYSCALE) #aloeL.jpg\n",
    "    img_r = cv2.imread('kitti00_00r.png', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img_disp = compute_disparity(img_l, img_r)\n",
    "    img_depth = compute_depth(f, T, img_disp)\n",
    "    point_cloud = generate_point_cloud(K, img_depth)\n",
    "    view_point_cloud(point_cloud)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sumário\n",
    "\n",
    "Nesta aula - reconstrução estéreo:\n",
    "\n",
    "- Correspondência estéreo\n",
    "- Triangulação com imagens retificadas\n",
    "- Reconstrução de imagens em nuvens de pontos 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referências:\n",
    "\n",
    "[1] R. Szeliski. 2010. Computer Vision: Algorithms and Applications (1st. ed.). Springer.\n",
    "\n",
    "[2] E. Trucco and A. Verri. 1998. Introductory Techniques for 3-D Computer Vision. Prentice Hall PTR, USA.\n",
    "\n",
    "[3] A. Kaehler and G. Bradski. 2014. Learning OpenCV, 2nd Edition. O'Reilly Media, Inc.\n",
    "\n",
    "[4] KITTI Vision Benchmark Suite.<br>\n",
    "    Disponível em https://www.cvlibs.net/datasets/kitti/eval_odometry.php"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
