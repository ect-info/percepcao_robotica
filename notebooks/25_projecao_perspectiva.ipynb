{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table style=\"width: 100%; margin-left: auto; margin-right: auto;\" border=\"0\">\n",
    "    <tr>\n",
    "        <td rowspan=\"3\"> <img src=\"brasao_ufrn.png\" width=\"150\"/> </td>\n",
    "        <td style=\"text-align: center\">  Escola de Ciências e Tecnologia </td>\n",
    "        <td rowspan=\"3\" style=\"text-align: center\"> UFRN<br> CT<br> PPGEMECA </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: center\"> PPGEMECA - Percepção Robótica </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p style=\"text-align: left;\">Prof. Bruno Silva<br>\n",
    "                                         Prof. Marcelo Nogueira</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometria em Visão Computacional I\n",
    "\n",
    "- Precisamos de modelar matematicamente o processo **geométrico** de formação de imagem\n",
    "- Isto é necessário para aplicações que necessitem da geometria da cena:\n",
    "    - Construção de mosaicos/panoramas\n",
    "    - Reconstrução 3D\n",
    "    - SLAM\n",
    "    - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometria em Visão Computacional II\n",
    "\n",
    "A partir de um modelo matemático, é possível estabelecer uma relação\n",
    "entre coordenadas de objetos da cena (3D) e coordenadas de imagem (2D).\n",
    "\n",
    "Isto é feito através de um modelo matemático de projeção perspectiva\n",
    "conhecido como câmera *pinhole*.\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"25_projecao_perspectiva/pinhole_model.png\" style=\"margin:auto; width: 600px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "Imagem de [3].\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometria em Visão Computacional III\n",
    "\n",
    "Pergunta que você deverá saber responder até o fim da aula:\n",
    "\n",
    "> É possível obter as coordenadas 3D de uma feature, dadas as suas coordenadas 2D em uma única imagem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometria: Sistemas de Coordenadas Envolvidos\n",
    "\n",
    "No geral, existem 3 Sistemas de Coordenadas envolvidos no processo de projeção de um ponto 3D:\n",
    "\n",
    "- Sistema de coordenadas 3D de mundo $\\mathbf{W}$\n",
    "- Sistema de coordenadas 3D de câmera $\\mathbf{C}$\n",
    "- Sistema de coordenadas 2D de imagem (eixos $\\mathbf{x}_{im}$ e $\\mathbf{y}_{im}$)\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"25_projecao_perspectiva/involved_coordinates_systems.png\" style=\"margin:auto; width: 300px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "Sistemas de coordenadas de mundo, câmera e imagem.\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Observe que o S.C. de câmera possui os seus eixos $\\mathbf{x}_c$ e $\\mathbf{y}_c$ orientados de forma que o<br>\n",
    "S.C. de imagem possui direção horizontal crescente para a direita e direção vertical<br>\n",
    "crescente para baixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometria: Parâmetros Envolvidos\n",
    "\n",
    "O processo geométrico de formação de imagem é dividido em 2 conjuntos\n",
    "de parâmetros:\n",
    "\n",
    "- Parâmetros extrínsecos $\\rightarrow$ relacionam a câmera com a cena\n",
    "- Parâmetros intrínsecos $\\rightarrow$ contêm características da câmera necessários para projeção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parâmetros Extrínsecos: Transformação entre Sistemas de Coordenadas I\n",
    "\n",
    "Parâmetros **extrínsecos**: \n",
    "\n",
    "- $\\mathbf{R}_{c,w}$: matriz de rotação \n",
    "- $\\mathbf{t}_{c,w}$: vetor de translação\n",
    "\n",
    "Transformam pontos de coordenadas de mundo para coordenadas de câmera $\\rightarrow$ transformam $\\mathbf{P}_w$ em $\\mathbf{P}_c$:\n",
    "\n",
    "$$\n",
    "P_c = \\mathbf{R}_{c,w} P_w + \\mathbf{t}_{c,w}\n",
    "$$\n",
    "\n",
    "Em geral, cada imagem está associada a um par $\\mathbf{R}_{c,w}$, $\\mathbf{t}_{c,w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parâmetros Extrínsecos: Transformação entre Sistemas de Coordenadas II\n",
    "\n",
    "Os parâmetros extrínsecos podem ser convenientemente representados\n",
    "por uma matriz de transformação de corpo rígido $\\mathbf{T}_{c,w}$:\n",
    "\n",
    "$$\n",
    "\\tilde{P}_c = \\mathbf{T}_{c,w}\\tilde{P}_w,\n",
    "$$\n",
    "\n",
    "$$\n",
    "T_{c,w} =\n",
    "\\left[\n",
    "\\begin{array}{c|c}\n",
    "\\mathbf{R}_{c,w} && \\mathbf{t}_{c,w}\\\\\n",
    "\\mathbf{0} && 1\n",
    "\\end{array}\n",
    "\\right]_{4x4},\n",
    "$$\n",
    "\n",
    "com $\\tilde{P}_c$ e $\\tilde{P}_w$ sendo os pontos em coordenadas de câmera e mundo dados em coordenadas homogêneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo de Projeção Perspectiva I\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"25_projecao_perspectiva/pinhole_camera01.png\" style=\"margin:auto; width: 400px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "Projeção perspectiva no modelo de câmera pinhole.\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Precisamos de um modelo que realize a projeção de pontos 3D em pontos 2D,\n",
    "dados:\n",
    "\n",
    "- O plano de imagem $\\pi$\n",
    "- O centro da câmera $\\mathbf{C}$ (centro de projeção)\n",
    "- A distância focal $f$ (distância entre $\\pi$ e $\\mathbf{C}$)\n",
    "- O eixo óptico (linha $\\overrightarrow{C\\mathbf{z}_c}$, é perpendicular ao plano de imagem)\n",
    "- Centro da imagem $\\mathbf{c}$ (intersecção do eixo óptico com $\\pi$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo de Projeção Perspectiva II\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"25_projecao_perspectiva/pinhole_camera02.png\" style=\"margin:auto; width: 300px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td colspan=\"2\">\n",
    "Projeção perspectiva no modelo de câmera pinhole (corte lateral).\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "De forma simplificada, o modelo computa $\\mathbf{p} = [x,y]^t$,<br>\n",
    "a projeção 2D na imagem de um ponto 3D $\\mathbf{P}_c = [X_c,Y_c,Z_c]^t$,<br>\n",
    "utilizando semelhança de triângulos:\n",
    "\n",
    "$$\n",
    "\\frac{x}{f} = \\frac{X_c}{Z_c} \\rightarrow x = f\\frac{X_c}{Z_c}\n",
    "$$\n",
    "$$\n",
    "\\frac{y}{f} = \\frac{Y_c}{Z_c} \\rightarrow y = f\\frac{Y_c}{Z_c}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo de Projeção Perspectiva III\n",
    "\n",
    "Entretanto, o processo descrito resulta em $\\mathbf{p}$\n",
    "dado nas mesmas unidades de comprimento de $\\mathbf{P}_c$.\n",
    "\n",
    "É preciso que o modelo matemático compute $\\mathbf{p}$\n",
    "em pixels.\n",
    "\n",
    "Para isto, utilizamos os parâmetros **intrínsecos** de câmera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parâmetros Intrínsecos: Projeção Perspectiva I\n",
    "\n",
    "Parâmetros **intrínsecos**:\n",
    "\n",
    "- Distâncias focais $f_x$ e $f_y$: convertidas para pixels depois de serem multiplicadas pela densidade do sensor (pixels/mm)\n",
    "- Coordenadas de imagem do centro de projeção $c_x$ e $c_x$: transformam a origem do S.C. de imagem do meio da imagem para o canto superior esquerdo\n",
    "- Estão embutidos na matriz de parâmetros intrínsecos (ou matriz de câmera) $\\mathbf{K}$\n",
    "\n",
    "A partir da matriz de parâmetros intrínsecos é possível transformar $\\mathbf{P}_c$ em $\\mathbf{p}$\n",
    "utilizando multiplicação matricial:\n",
    "\n",
    "$$\n",
    "s\\mathbf{p} = \\mathbf{K}\\mathbf{P}_c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parâmetros Intrínsecos: Projeção Perspectiva II\n",
    "\n",
    "Especificamente, $\\mathbf{K}$ contém os parâmetros $f_x$, $f_y$, $c_x$ e $c_y$ como sendo\n",
    "\n",
    "$$\n",
    "s\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "f_x &   0 & c_x\\\\\n",
    "  0 & f_y & c_y\\\\\n",
    "  0 &   0 &   1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_c\\\\\n",
    "Y_c\\\\\n",
    "Z_c\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "com $s$ sendo um parâmetro de escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parâmetros Intrínsecos: Projeção Perspectiva III\n",
    "\n",
    "As coordenadas $[x,y]^t$ de um ponto na imagem são então obtidas por\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "sx &= f_x X_c + c_x Z_c,\\\\\n",
    "sy &= f_y Y_c + c_y Z_c,\\\\\n",
    "s &= Z_c\n",
    "\\end{align*},\n",
    "$$\n",
    "\n",
    "dividindo-se em seguida $[sx, sy, s]^t$ por $s$,\n",
    "\n",
    "$$\n",
    "x = f_x \\frac{X_c}{Z_c} + c_x,\n",
    "$$\n",
    "$$\n",
    "y = f_y \\frac{Y_c}{Z_c} + c_y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observações sobre a Projeção Perspectiva:\n",
    "\n",
    "É importante ter em mente alguns fatos sobre a projeção perspectiva:\n",
    "\n",
    "- É não-linear (divisão por $Z_c$)\n",
    "- A informação $Z_c$ (i.e. escala $s$) se perde no processo de projeção\n",
    "- Não preserva ângulos entre linhas: linhas paralelas no mundo podem ser projetadas para linhas não paralelas na imagem\n",
    "- Não preserva distâncias entre pontos (nem mesmo considerando proporções)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parâmetros de Distorção I\n",
    "\n",
    "O uso de lentes no modelo de câmera *pinhole* introduz _distorções_\n",
    "nos pixels de uma imagem. Observe o exemplo abaixo:\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"25_projecao_perspectiva/szeliski_distortion_example.png\" style=\"margin:auto; width: 800px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Imagem de [1]</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parâmetros de Distorção II\n",
    "\n",
    "As mais frequentes distorções em imagens são as do tipo *radial*, que se dividem\n",
    "em:\n",
    "\n",
    "- Distorção barril\n",
    "- Distorção *pincushion*\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr>\n",
    "<td><img src=\"25_projecao_perspectiva/opencv_distortion_examples1.png\" style=\"margin:auto; width: 800px;\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Imagem de [4]</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo de Distorção I\n",
    "\n",
    "Como pode-ser perceber, utilizar imagens capturadas por uma\n",
    "câmera diretamente nas aplicações (ex. SLAM),<br>\n",
    "sem considerar as distorções das lentas, faz com que erros consideráveis sejam introduzidos no processo.\n",
    "\n",
    "É necessário então modelar matematicamente a distorção de pontos com\n",
    "parâmetros intrínsecos adicionais chamados<br>\n",
    "parâmetros **de distorção**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo de Distorção II\n",
    "\n",
    "O modelo matemático de distorção utilizado em câmeras pespectivas consideram:\n",
    "\n",
    "- **Distorção radial**, com parâmetros $k_1$, $k_2$, $k_3$ (e quando necessário, até de ordens mais altas)\n",
    "- **Distorção tangencial**, com parâmetros $p_1$ e $p_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Projeção com Distorção: passos\n",
    "\n",
    "Para obter as coordenadas de imagem $[x,y]^t$ de um ponto qualquer considerando\n",
    "distorções, procede-se da seguinte forma:\n",
    "\n",
    "1. Calcula-se as coordenadas do ponto dividindo-o pela sua profundidade, mas sem multiplicar pela distância focal\n",
    "2. Aplica-se o modelo de distorção radial e tangencial (mostrado a seguir) a estas coordenadas\n",
    "3. Multiplica-se as coordenadas resultantes pelas distâncias focais e soma-se os centros de projeção\n",
    "\n",
    "O processo é mostrado com mais detalhes a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distorção: passo 1\n",
    "\n",
    "Calcula-se as coordenadas $[x',y']^t$ (projeção sem multiplicar pela distância focal):\n",
    "\n",
    "$$\n",
    "x' = \\frac{X_c}{Z_c},\n",
    "$$\n",
    "$$\n",
    "y' = \\frac{Y_c}{Z_c}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distorção: passo 2\n",
    "\n",
    "Aplica-se o modelo de distorção radial e tangencial a $[x',y']^t$:\n",
    "\n",
    "$$\n",
    "x'' = x'(1 + k_1r^2 + k_2r^4 + k_3r^6) + 2p_1x'y' + p_2(r^2 + 2x'^2),\n",
    "$$\n",
    "$$\n",
    "y'' = y'(1 + k_1r^2 + k_2r^4 + k_3r^6) + p_1(r^2 + 2y'^2) + 2p_2x'y',\n",
    "$$\n",
    "\n",
    "onde\n",
    "\n",
    "$$\n",
    "r^2 = x'^2 + y'^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distorção: passo 3\n",
    "\n",
    "Multiplica-se as coordenadas resultantes $[x'', y'']^t$ pelas distâncias focais e soma-se os centros de projeção:\n",
    "\n",
    "$$\n",
    "x = f_x x'' + c_x,\n",
    "$$\n",
    "$$\n",
    "y = f_y y'' + c_y\n",
    "$$\n",
    "\n",
    "O vetor $[x,y]^t$ irá conter as coordenadas do ponto considerando a distorção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observações sobre Distorção em Imagens\n",
    "\n",
    "Em aplicações reais, aplica-se o modelo de distorção a cada pixel da imagem,\n",
    "de forma que toda a imagem é distorcida (transformações de *warping*).\n",
    "\n",
    "Este processo irá resultar em várias áreas com regiões com valor 0 para\n",
    "os pixels na imagem (regiões pretas).\n",
    "\n",
    "Então, a imagem é cortada (*crop*), de forma que apenas a área útil da imagem\n",
    "seja utilizada.\n",
    "\n",
    "Com o novo tamanho da imagem, as distâncias focais e coordenadas\n",
    "do centro de projeção devem ser recomputadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Próximos Passos\n",
    "\n",
    "Para aplicar os modelo estudado, é preciso\n",
    "calcular os seus parâmetros.<br>\n",
    "Para isto:\n",
    "\n",
    "Algoritmos de calibração de câmera (próxima aula)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sumário\n",
    "\n",
    "Nesta aula - modelo geométrico de geração de imagem:\n",
    "\n",
    "- Parâmetros extrínsecos\n",
    "- Parâmetros intrínsecos (com e sem distorção)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Referências:\n",
    "\n",
    "[1] R. Szeliski. 2010. Computer Vision: Algorithms and Applications (1st. ed.). Springer.\n",
    "\n",
    "[2] E. Trucco and A. Verri. 1998. Introductory Techniques for 3-D Computer Vision. Prentice Hall PTR, USA.\n",
    "\n",
    "[3] A. Kaehler and G. Bradski. 2014. Learning OpenCV, 2nd Edition. O'Reilly Media, Inc.\n",
    "\n",
    "[4] OpenCV Documentation: Camera Calibration and 3D Reconstruction.<br>\n",
    "    Disponível em https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
